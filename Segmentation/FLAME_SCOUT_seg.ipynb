{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for downloading files\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "#  imports for the network\n",
    "import torchvision, torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "folder_path = \"/home/xurxo/Documentos/Asignaturas Master/Semestre_1/Deep_Learning/practicas/project/Dataset/Segmentation\"\n",
    "\n",
    "image_path = folder_path + \"/Images\"\n",
    "mask_path = folder_path + \"/Masks\"\n",
    "\n",
    "\"\"\"\n",
    "Creation of the dataset: It comprises\n",
    "two folders, one for the images and one for the masks.\n",
    "The idea is to create a map between the images and the masks, \n",
    "then splitting into train, validation and testing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "image_files = os.listdir(image_path)\n",
    "mask_files = os.listdir(mask_path)\n",
    "\n",
    "image_mapping = {}\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_name = os.path.splitext(image_file)[0]\n",
    "    mask_file = image_name + \".png\"\n",
    "    \n",
    "    if mask_file in mask_files:\n",
    "        image_mapping[image_file] = mask_file\n",
    "\n",
    "print(image_mapping)\n",
    "\n",
    "#now we split the dataset into train(70), validation(15) and test (15)\n",
    "\n",
    "# Split the image_mapping into train, validation, and test subsets\n",
    "train_mapping, test_mapping = train_test_split(list(image_mapping.items()), test_size=0.3, random_state=42)\n",
    "validation_mapping, test_mapping = train_test_split(test_mapping, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert the train, validation, and test mappings back to dictionaries\n",
    "train_mapping = dict(train_mapping)\n",
    "validation_mapping = dict(validation_mapping)\n",
    "test_mapping = dict(test_mapping)\n",
    "\n",
    "# Print the train, validation, and test mappings\n",
    "print(\"Train Mapping:\")\n",
    "print(train_mapping)\n",
    "print(\"Validation Mapping:\")\n",
    "print(validation_mapping)\n",
    "print(\"Test Mapping:\")\n",
    "print(test_mapping)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
