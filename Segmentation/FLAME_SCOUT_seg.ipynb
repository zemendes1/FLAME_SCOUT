{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for downloading files\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "#  imports for the network\n",
    "import torchvision, torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading zip file...\n",
      "Downloading zip file...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown url type: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m urls:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# Download the zip file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDownloading zip file...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     u \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     data \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mread()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josemendes/Documents/FLAME_SCOUT/Segmentation/FLAME_SCOUT_seg.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     u\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:503\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, fullurl, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, timeout\u001b[39m=\u001b[39msocket\u001b[39m.\u001b[39m_GLOBAL_DEFAULT_TIMEOUT):\n\u001b[1;32m    501\u001b[0m     \u001b[39m# accept a URL or a Request object\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fullurl, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 503\u001b[0m         req \u001b[39m=\u001b[39m Request(fullurl, data)\n\u001b[1;32m    504\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         req \u001b[39m=\u001b[39m fullurl\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:322\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{},\n\u001b[1;32m    320\u001b[0m              origin_req_host\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, unverifiable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    321\u001b[0m              method\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_url \u001b[39m=\u001b[39m url\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders \u001b[39m=\u001b[39m {}\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munredirected_hdrs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:348\u001b[0m, in \u001b[0;36mRequest.full_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url \u001b[39m=\u001b[39m unwrap(url)\n\u001b[1;32m    347\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfragment \u001b[39m=\u001b[39m _splittag(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url)\n\u001b[0;32m--> 348\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:377\u001b[0m, in \u001b[0;36mRequest._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype, rest \u001b[39m=\u001b[39m _splittype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munknown url type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_url)\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector \u001b[39m=\u001b[39m _splithost(rest)\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost:\n",
      "\u001b[0;31mValueError\u001b[0m: unknown url type: ''"
     ]
    }
   ],
   "source": [
    "# Get files in current working directory\n",
    "files = os.listdir()\n",
    "\n",
    "\n",
    "# This url points to the download of the .zip file for the masks\n",
    "masks_url = \"\"\n",
    "\n",
    "# This url points to the download of the .zip file for the masks\n",
    "images_url = \"\"\n",
    "\n",
    "urls =  [masks_url, images_url]\n",
    "\n",
    "for url in urls:\n",
    "    # Download the zip file\n",
    "    print(\"Downloading zip file...\")\n",
    "    u = urllib.request.urlopen(url)\n",
    "    data = u.read()\n",
    "    u.close()\n",
    "\n",
    "    zip_filename = \"\"\n",
    "    if url == masks_url:\n",
    "        # Specify the local filename for the downloaded zip file\n",
    "        zip_filename = 'Masks.zip'\n",
    "    elif url == images_url:\n",
    "        # Specify the local filename for the downloaded zip file\n",
    "        zip_filename = 'Images.zip'\n",
    "\n",
    "    with open(zip_filename, 'wb') as f:\n",
    "        f.write(data)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        # Extract all contents to the current working directory\n",
    "        zip_ref.extractall()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_path,masks_path, transform):\n",
    "        self.data = []\n",
    "        self.image_path = image_path\n",
    "        self.masks_path = masks_path\n",
    "        self.img_dim=(3840, 2160)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_file_list = glob.glob(self.image_path + \"/*.jpg\")\n",
    "        self.masks_file_list = glob.glob(self.masks_path + \"/*.png\")\n",
    "\n",
    "        for i in range(0,len(self.image_file_list)):\n",
    "                \n",
    "                img = cv2.imread(self.image_file_list[i])[..., ::-1]  # Convert BGR to RGB\n",
    "                img = cv2.resize(img, self.img_dim)\n",
    "                img_tensor = self.transform(img)\n",
    "\n",
    "                mask = cv2.imread(self.masks_file_list[i], cv2.IMREAD_UNCHANGED)\n",
    "                mask = mask * 255\n",
    "                masks_path = cv2.resize(mask, self.img_dim)\n",
    "                mask_tensor = self.transform(mask)\n",
    "\n",
    "                self.data.append([img_tensor, mask_tensor])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def get_data (self):\n",
    "\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[[0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         ...,\n",
      "         [0.6235, 0.6235, 0.6235,  ..., 0.6314, 0.6314, 0.6353],\n",
      "         [0.6235, 0.6235, 0.6235,  ..., 0.6314, 0.6314, 0.6353],\n",
      "         [0.6235, 0.6235, 0.6235,  ..., 0.6314, 0.6314, 0.6353]],\n",
      "\n",
      "        [[0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         [0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         [0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         ...,\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6431, 0.6431, 0.6471],\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6431, 0.6431, 0.6471],\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6431, 0.6431, 0.6471]],\n",
      "\n",
      "        [[0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         [0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         [0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         ...,\n",
      "         [0.6510, 0.6510, 0.6510,  ..., 0.6627, 0.6627, 0.6667],\n",
      "         [0.6510, 0.6510, 0.6510,  ..., 0.6627, 0.6627, 0.6667],\n",
      "         [0.6510, 0.6510, 0.6510,  ..., 0.6627, 0.6627, 0.6667]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])], [tensor([[[0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         ...,\n",
      "         [0.6235, 0.6235, 0.6235,  ..., 0.6235, 0.6235, 0.6235],\n",
      "         [0.6235, 0.6235, 0.6235,  ..., 0.6275, 0.6235, 0.6196],\n",
      "         [0.6235, 0.6235, 0.6235,  ..., 0.6275, 0.6275, 0.6196]],\n",
      "\n",
      "        [[0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         [0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         [0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         ...,\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6353, 0.6353, 0.6353],\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6392, 0.6353, 0.6314],\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6392, 0.6392, 0.6314]],\n",
      "\n",
      "        [[0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         [0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         [0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         ...,\n",
      "         [0.6510, 0.6510, 0.6510,  ..., 0.6549, 0.6549, 0.6549],\n",
      "         [0.6510, 0.6510, 0.6510,  ..., 0.6588, 0.6549, 0.6510],\n",
      "         [0.6510, 0.6510, 0.6510,  ..., 0.6588, 0.6588, 0.6510]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])], [tensor([[[0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "         ...,\n",
      "         [0.6196, 0.6196, 0.6235,  ..., 0.6314, 0.6353, 0.6353],\n",
      "         [0.6157, 0.6118, 0.6078,  ..., 0.6314, 0.6353, 0.6353],\n",
      "         [0.6118, 0.6118, 0.6118,  ..., 0.6353, 0.6353, 0.6353]],\n",
      "\n",
      "        [[0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         [0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         [0.1373, 0.1373, 0.1373,  ..., 0.1804, 0.1804, 0.1804],\n",
      "         ...,\n",
      "         [0.6353, 0.6353, 0.6392,  ..., 0.6431, 0.6471, 0.6471],\n",
      "         [0.6314, 0.6275, 0.6235,  ..., 0.6431, 0.6471, 0.6471],\n",
      "         [0.6275, 0.6275, 0.6275,  ..., 0.6471, 0.6471, 0.6471]],\n",
      "\n",
      "        [[0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         [0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         [0.0941, 0.0941, 0.0941,  ..., 0.2157, 0.2157, 0.2157],\n",
      "         ...,\n",
      "         [0.6471, 0.6471, 0.6510,  ..., 0.6627, 0.6667, 0.6667],\n",
      "         [0.6431, 0.6392, 0.6353,  ..., 0.6627, 0.6667, 0.6667],\n",
      "         [0.6392, 0.6392, 0.6392,  ..., 0.6667, 0.6667, 0.6667]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#now we split the dataset into train(70), validation(15) and test (15)\\n\\n# Split the image_mapping into train, validation, and test subsets\\ntrain_mapping, test_mapping = train_test_split(list(image_mapping.items()), test_size=0.3, random_state=42)\\nvalidation_mapping, test_mapping = train_test_split(test_mapping, test_size=0.5, random_state=42)\\n\\n# Convert the train, validation, and test mappings back to dictionaries\\ntrain_mapping = dict(train_mapping)\\nvalidation_mapping = dict(validation_mapping)\\ntest_mapping = dict(test_mapping)\\n\\n# Print the train, validation, and test mappings\\nprint(\"Train Mapping:\")\\nprint(train_mapping)\\nprint(\"Validation Mapping:\")\\nprint(validation_mapping)\\nprint(\"Test Mapping:\")\\nprint(test_mapping)\\n\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"Images\"\n",
    "mask_path = \"Masks\"\n",
    "\n",
    "image_files = os.listdir(image_path)\n",
    "mask_files = os.listdir(mask_path)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = FireDataset(image_path,mask_path, transform)\n",
    "length = FireDataset.__len__(dataset)\n",
    "print(dataset.get_data())\n",
    "\n",
    "\"\"\"\n",
    "#now we split the dataset into train(70), validation(15) and test (15)\n",
    "\n",
    "# Split the image_mapping into train, validation, and test subsets\n",
    "train_mapping, test_mapping = train_test_split(list(image_mapping.items()), test_size=0.3, random_state=42)\n",
    "validation_mapping, test_mapping = train_test_split(test_mapping, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert the train, validation, and test mappings back to dictionaries\n",
    "train_mapping = dict(train_mapping)\n",
    "validation_mapping = dict(validation_mapping)\n",
    "test_mapping = dict(test_mapping)\n",
    "\n",
    "# Print the train, validation, and test mappings\n",
    "print(\"Train Mapping:\")\n",
    "print(train_mapping)\n",
    "print(\"Validation Mapping:\")\n",
    "print(validation_mapping)\n",
    "print(\"Test Mapping:\")\n",
    "print(test_mapping)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
